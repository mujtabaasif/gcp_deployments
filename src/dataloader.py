import json
from pathlib import Path
from typing import List, Union, Dict, Tuple, Optional

from pydantic import BaseModel, Field


class Document(BaseModel):
    pre_text: str = Field(description="The text before the table in the document")
    post_text: str = Field(description="The text after the table in the document")
    table: Dict[str, Dict[str, Union[float, str, int]]] = Field(
        description="The table of the document as a dictionary"
    )


class Dialogue(BaseModel):
    conv_questions: List[str] = Field(
        description="The questions in the conversation dialogue"
    )
    conv_answers: List[str] = Field(
        description="The answers to each question turn"
    )
    turn_program: List[str] = Field(
        description="The DSL turn program for each question turn"
    )
    executed_answers: List[Union[float, str]] = Field(
        description="The golden program execution results for each question turn"
    )
    qa_split: List[bool] = Field(
        description="0 if from first FinQA question, 1 if from second (Type II)"
    )
    llm_answers: Optional[List[str | None]] = Field(
        default_factory=list,
        description="The answers generated by the LLM for each question turn",
    )
    extracted_answers: Optional[List[bool | None]] = Field(
        default_factory=list,
        description="The answers extracted from the table for each question turn"
    )


class Features(BaseModel):
    num_dialogue_turns: int = Field(
        description="The number of turns in the dialogue"
    )
    has_type2_question: bool = Field(
        description="Whether the dialogue has a type 2 question"
    )
    has_duplicate_columns: bool = Field(
        description="Whether the table has duplicate column names"
    )
    has_non_numeric_values: bool = Field(
        description="Whether the table has non-numeric values"
    )


class State(BaseModel):
    question: str = Field(description="The current question being processed")
    context: str = Field(description="The context for the current question")
    retriever: str = Field(description="The retrieved information for the question")
    skip_generation: bool = Field(default=False, description="Whether to skip generation for this state")
    steps_generated: str = Field(description="The generated steps for the question")
    executor: str = Field(description="The executor for the generated steps")
    answer: str = Field(description="The final answer to the question")
    retrieval_history: List[Dict[str, str]] = Field(
        default_factory=list,
        description="History of retrievals, each entry is a dict with 'user' and 'assistant' keys"
    )
    generation_history: List[Dict[str, str]] = Field(
        default_factory=list,
        description="History of generations, each entry is a dict with 'user' and 'assistant' keys"
    )
    history: List[Dict[str, str]] = Field(
        default_factory=list,
        description="Full conversation history, each entry is a dict with 'user' and 'assistant' keys"
    )


class ConvFinQARecord(BaseModel):
    id: str = Field(description="The id of the record")
    doc: Document = Field(description="The document")
    dialogue: Dialogue = Field(description="The conversational dialogue")
    features: Features = Field(description="Additional metadata")
    response_state: List[State] = Field(
        default_factory=list,
        description="The state of the response, including question, context, retriever, steps generated, executor, and answer"
    )


def load_convfinqa_dataset(path: str) -> Tuple[List[ConvFinQARecord], List[ConvFinQARecord]]:
    if not Path(path).is_file():
        raise FileNotFoundError(f"The file {path} does not exist.")

    with open(path, 'r', encoding='utf-8') as file:
        data = json.load(file)

    train_data = data.get('train', [])
    test_data = data.get('dev', [])
    train_data = [ConvFinQARecord(**record) for record in train_data]
    test_data = [ConvFinQARecord(**record) for record in test_data]

    return train_data, test_data


def load_convfinqa_dataset_eval(path: str) -> List[ConvFinQARecord]:
    if not Path(path).is_file():
        raise FileNotFoundError(f"The file {path} does not exist.")

    with open(path, 'r', encoding='utf-8') as file:
        data = json.load(file)

    data = [ConvFinQARecord(**record) for record in data]

    return data


if __name__ == "__main__":
    dataset_path = "../data/convfinqa_dataset.json"
    train_set, test_set = load_convfinqa_dataset(dataset_path)

    print(f"Loaded {len(train_set)} training records and {len(test_set)} test records.")
    # Example of accessing a record
    if train_set:
        print(f"First training record ID: {train_set[0].id}")
        print(f"First training record dialogue questions: {train_set[0].dialogue.conv_questions}")
        print(f"First training record dialogue questions: {train_set[0].dialogue.conv_answers}")
        print(f"First training record table: {train_set[0].doc.table}")
    else:
        print("No training records found.")

    if test_set:
        print(f"First test record ID: {test_set[0].id}")
        print(f"First test record dialogue questions: {test_set[0].dialogue.conv_questions}")
        print(f"First test record dialogue answers: {test_set[0].dialogue.conv_answers}")
        print(f"First test record table: {test_set[0].doc.table}")
    else:
        print("No test records found.")
